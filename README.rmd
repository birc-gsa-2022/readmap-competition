---
title: "Performance report"
output: md_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
```

```{r helpers}
lang <- function(proj) {
  proj |> 
    str_to_lower() |>
    when(
      str_starts(., "python")    ~ "Python",
      str_starts(., "go")        ~ "Go",
      str_starts(., "c-cmake")   ~ "C",
      str_starts(., "c")         ~ "C",
      ~ "Unknown"
    )
}

cut_lang <- function(lang, proj) {
  lang |> when(
    (. == "Python") ~ str_replace(proj, "python-", ""),
    (. == "Go")     ~ str_replace(proj, "go-", ""),
    (. == "C")      ~ proj |> str_replace("c-cmake-", "") |> str_replace("c-", "")
  )
}

rename_mine <- function(proj) {
  proj |> 
    when(
      str_starts(., "readmap") ~ {
        x <- str_split(., "-", n = 2)
        paste0(x[[1]][2], '-mailund')
      },
      ~ proj
    )
}

transform_projects <- function(data) {
  data |>
    mutate(
      Tool = str_to_lower(Tool) |> str_replace_all("\\.", "-") |> str_replace("project-5-",""),
      Tool = map_chr(Tool, rename_mine),
      Language = map_chr(Tool, lang),
      Tool = map2_chr(Language, Tool, cut_lang) |> str_to_title() |> str_replace_all("-", " "),
      Language = fct_relevel(Language, "Python", "Go", "C"),
    ) 
}

filter_genome <- function(data, chromlen) {
  data |> filter(Chromosome.length == chromlen)
}

genome_summary <- function(nochrom, chromlen) {
  paste0(nochrom, " chromosomes of length ", chromlen)
}

prep_title <- function(nochrom, chromlen) {
  ggtitle("Preprocessing", 
          subtitle = genome_summary(nochrom, chromlen)
  )
}

read_title <- function(chromlen, rlen, edits) {
  ggtitle("Read mapping", 
          subtitle = paste0(
            genome_summary(10, chromlen),
            " with read length ", rlen, " and ", edits, " as max edits"
          ))
}
```

<!-- ## Status of projects -->

<!--
```{r, results='asis'}
status <- read.table('res/status.txt', header = TRUE) |>
  transform(Project = str_replace(Project, "project-5-","")) |>
  mutate(Language = map_chr(Project, lang)) |>
  transform(Team = map2_chr(Language, Project, cut_lang)) |>
  select(Team, Language, Status)
knitr::kable(status, "pipe")
```
-->

## Preprocessing performance (all teams)

```{r read_perf}
load_pref <- function(fname) {
  read.csv(fname, header = TRUE) |>
  pivot_longer(-(Chromosomes:Chromosome.length), 
               names_to = "Tool", values_to = "Time") |>
  transform_projects()
}
```

```{r plot_short_perf}
plot_pref_perf <- function(pre_perf) {
  chrom_lens <- unique(pre_perf$Chromosome.length)
  for (clen in chrom_lens) {
      chrom_data <- pre_perf |> 
        filter_genome(clen) |>
        mutate(TL = str_c(Tool, ' [', Language, ']')) |>
        group_by(TL) |> 
        mutate(meanTime = mean(Time))
      # I have *no* idea why this doesn't work in a mutate any more, but fuck it
      chrom_data$TL = fct_reorder(chrom_data$TL, desc(chrom_data$meanTime))

    plt <- chrom_data |> 
      ggplot(aes(x = TL, y = Time, colour = Language, fill = Language)) +
      geom_violin() +
      facet_grid(. ~ Chromosome.length, scales = "free_x", space = "free_x") +
      xlab("") +
      scale_x_discrete(breaks=chrom_data$TL, labels=chrom_data$Tool) +
      theme_classic() +
      scale_fill_brewer(palette="Set2") +
      scale_colour_brewer(palette="Set2") +
      theme(legend.position="bottom", 
            axis.text.x = element_text(angle = -15, vjust = 1.5, hjust=0)) +
      prep_title(10, clen)
    print(plt)
  }
}
```

I first ran all tools on small data sets (genomes with 10 chromosomes of length 2500 or 5000). This is a truly tiny size for a genome, and everyone should be able to handle that. After that, we can compare the faster tools with larger genomes.

I have included all student projects plus three of my own: one read-mapper in each language (Python, Go, and C). My own implementations are roughly equivalent, except for language, and except where language features makes one solution more natural than another: for Go, using closures to iterate through solutions while in Python you more naturally use generators, and in C I use a state machine.

Without further ado, here are the results:

```{r plot_short_pref}
short_pre <- rbind(load_pref("res/short-preprocessing.txt"),
                   load_pref("res/short-preprocessing-backup.txt"))
short_pre|> plot_pref_perf()
```

The solutions are sorted in descending order according to their mean running time over 20 repeats, so the father right you get, the faster the tool.

Except for a few outliers at the left end, the tools have comparable running time. This is partly because we are looking at such a small data set (spoiler alert) and because the slow contestants push the other tools down close to zero when I fit all the time measurements on the same y-axis.

If we remove the two slowest teams we get a bit more detail for the rest:

```{r}
short_pre |> filter(!(Tool %in% c("Illiterate Apes", "Holdet"))) |> plot_pref_perf()
```

## Mapping performance (all teams)

The preprocessing isn't everything, of course. As long as it is fast enough to handle a genome in reasonable time, it is more important that the mapping is fast. You tend to only preprocess a genome once, but you will map against it many times.

So, I measured the time it would take to map reads of length 200 (a small to medium length for reads) allowing one or two edits against the two sizes of genomes.

```{r read_map}
load_mapping <- function(fname) {
  read.csv(fname, header = TRUE) |>
  pivot_longer(-(Chromosomes:Edits), names_to = "Tool", values_to = "Time") |>
  transform_projects()
}
```

```{r plot_map}
plot_mapping <- function(map_perf) {
  chrom_lens <- unique(map_perf$Chromosome.length)
  read_lengths <- unique(map_perf$Read.length)
  edits <- unique(map_perf$Edits)
  
  for (clen in chrom_lens) {
    for (rlen in read_lengths) {
      for (ed in edits) {
        chrom_data <- map_perf |> 
          filter_genome(clen) |>
          filter(Edits == ed) |>
          filter(Read.length == rlen) |>
          mutate(TL = str_c(Tool, ' [', Language, ']')) |>
          group_by(TL) |> 
          mutate(meanTime = mean(Time))
        # I have *no* idea why this doesn't work in a mutate any more, but fuck it
        chrom_data$TL = fct_reorder(chrom_data$TL, desc(chrom_data$meanTime))

        plt <- chrom_data |> 
          ggplot(aes(x = TL, y = Time, colour = Language, fill = Language)) +
          geom_violin() +
          #facet_grid(Read.length ~ ., scales = "free_x", space = "free_x") +
          xlab("") +
          scale_x_discrete(breaks=chrom_data$TL, labels=chrom_data$Tool) +
          theme_classic() +
          scale_fill_brewer(palette="Set2") +
          scale_colour_brewer(palette="Set2") +
          theme(legend.position="bottom", 
                axis.text.x = element_text(angle = -15, vjust = 1.5, hjust=0)) +
          read_title(clen, rlen, ed)
        print(plt)
      }
    }
  }
}
```

```{r plot_short_map}
short_map <- rbind(load_mapping("res/short-mapping.txt"),
                   load_mapping("res/short-mapping-backup.txt"))
short_map |> plot_mapping()
```

We are in much the same situation as with preprocessing, where it is hard to see how the majority of teams compare because of the extreme time the slowest tools use, but if we remove the two slowest again we get:

```{r}
short_map |> filter(!(Tool %in% c("Illiterate Apes", "Asg"))) |> plot_mapping()
```


## Longer genomes

Now let's take the data size up from toy examples to something within three or four orders of magnitude from real data for the tools that can handle that: we increase the chromosome lengths to 25,000 or 50,000. For small data sets, the running time can be affected by tiny algorithmic or programming choices, but when we increase the data we get a much better feeling of the overall quality of solutions. Based on the results above, I found it necessary to exclude "Illiterate Apes", "Team", and "Asg" from this part of the evaluation.

### Preprocessing

Again, let's first consider the preprocessing time:

```{r plot_long_pref}
pref_long <- load_pref("res/long-preprocessing.txt") 
pref_long |> plot_pref_perf()
```

It looks like the benefits you would expect from implementing in Go (for "Holdet") or C (for "O No") didn't quite compensate for some algorithmic choices in implementing the suffix array construction algorithm. If we remove these teams we can see how the remaining tools compare:

```{r}
pref_long |> filter(!(Tool %in% c("O No", "Holdet"))) |> plot_pref_perf()
```

There is not a huge difference any longer. The C and Go implementations have an unreasonable advantage by being compiled languages, but the Python tools are roughly the same.

### Mapping

Turning to mapping, I ran with reads of 200 and one or two edits, just as before. The results are these:

```{r plot_long_map}
long_map <- load_mapping("res/long-mapping.txt") 
long_map |> plot_mapping()
```

If we remove the slowest (sorry "Ms World Wides") we get:

```{r plot_long_map_small}
long_map |> filter(Tool != "Ms World Wides") |> plot_mapping()
```
